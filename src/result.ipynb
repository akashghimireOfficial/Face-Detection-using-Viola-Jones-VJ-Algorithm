{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "from os.path import join,abspath\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in paths.items():\n",
    "    paths[key]=join('..',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data': '../Data',\n",
       " 'original': '../Data/original',\n",
       " 'custom': '../Data/custom',\n",
       " 'neg_custom': '../Data/custom/n',\n",
       " 'custom_p': '../Data/custom/p',\n",
       " 'custom_p_train': '../Data/custom/p/train',\n",
       " 'custom_p_test': '../Data/Test/custom',\n",
       " 'sample': '../Data/custom/sample',\n",
       " 'public': '../Data/Public',\n",
       " 'neg_public': '../Data/Public/Negative',\n",
       " 'celeba': '../Data/Public/celeba',\n",
       " 'public_p': '../Data/Public/p',\n",
       " 'public_p_train': '../Data/Public/p/train',\n",
       " 'public_p_test': '../Data/Test/public',\n",
       " 'res': '../Result',\n",
       " 'res_cus': '../Result/Custom',\n",
       " 'res_pub': '../Result/Public',\n",
       " 'src': '../src',\n",
       " 'utils': '../utils',\n",
       " 'turtorial': '../turtorial'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading custom trained Haar classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_cascade = cv2.CascadeClassifier('../cascade.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained frontal face haar cascade classifier\n",
    ">Manually counting the number of faces in large samples of images creates errors.**Thus to obtain the ground truth related to number_of_faces we will be using pretrained cascade classifier xml file.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_cascade=cv2.CascadeClassifier('../haarcascade_frontalface_alt.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to Grayscale Image   ve_dire,img)\n",
    "def bgr2gray(img):\n",
    "   return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining funtion required for testing\n",
    "> Below is the function to count the total number of faces from a given test directory. It will return total number of faces detected from the given directory as well the amount of time it takes to detect those faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the total number of faces within images folder\n",
    "\n",
    "def test(classifier,dire):\n",
    "    face_count=0\n",
    "    start_time=time()\n",
    "    img_detected=0\n",
    "    for img_dire in dire:\n",
    "        img=cv2.imread(img_dire)\n",
    "        #img_name=img_dire.split('/')[-1].split('.')[0]\n",
    "        gray_img=bgr2gray(img)\n",
    "        faces_rect = classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=9)\n",
    "        if len(faces_rect)!=0:\n",
    "            img_detected+=1\n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            #print('ok')\n",
    "            face_count+=1\n",
    "    elapsed_time=time()-start_time\n",
    "    return face_count,elapsed_time,img_detected\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Accuracy and Processing time of Custom Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating the Accuracy of the cascade classifier. \n",
    "\n",
    "\n",
    "def get_acc(g_t,pred): ## if cust_dataset g_t =number of faces detected by pretrained model. for public dataset, g_t=len(images) in a folder\n",
    "    error=np.absolute(g_t-pred)\n",
    "    error_per=(error/g_t)*100\n",
    "    acc_per=(100-error_per)\n",
    "    return acc_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the precision time\n",
    "\n",
    "def time_per_face(face_count,elapsed_time):\n",
    "    return (elapsed_time/face_count)\n",
    "\n",
    "def time_per_image(num_image,elapsed_time):\n",
    "    return (elapsed_time/num_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function the minimum size of detected face size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minFace(img_dires):\n",
    "    min_siz=[]\n",
    "    for img_dire in img_dires:\n",
    "        img=cv2.imread(img_dire)\n",
    "        gray_img=bgr2gray(img)\n",
    "        test_arr=[1024,512,256,128,64,32,16,4,2,1][::-1]\n",
    "        for siz in test_arr:\n",
    "            faces_rect = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=9)\n",
    "            test_faces_rect=haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=9,minSize=(siz,siz))\n",
    "            if len(faces_rect)!=0 and len(test_faces_rect)==0:\n",
    "                min_siz.append(siz)\n",
    "    \n",
    "    return min(min_siz)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function the maximum size of detected face size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxFace(img_dires):\n",
    "    max_siz=[]\n",
    "    for img_dire in img_dires:\n",
    "        img=cv2.imread(img_dire)\n",
    "        gray_img=bgr2gray(img)\n",
    "        test_arr=[1024,512,256,128,64,32,16,4,2,1]\n",
    "        for siz in test_arr:\n",
    "            faces_rect = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=9)\n",
    "            test_faces_rect=haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=9,maxSize=(siz,siz))\n",
    "            if len(faces_rect)!=0 and len(test_faces_rect)==0:\n",
    "                max_siz.append(siz)\n",
    "    \n",
    "    return max(max_siz)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the cascade classifier on custom made Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_test_dires=glob(paths['custom_p_test']+'/*jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_t,_,_=test(classifier=pretrained_cascade,dire=cus_test_dires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_count,e_t,img_len=test(classifier=haar_cascade,dire=cus_test_dires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.0%\n"
     ]
    }
   ],
   "source": [
    "## Accuracy of the custom_face detection\n",
    "print('Accuracy: {}%'.format(get_acc(g_t,pred_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per face : 0.131842 sec.\n"
     ]
    }
   ],
   "source": [
    "### Average time per face\n",
    "print('Average time per face : {:03f} sec.'.format(time_per_face(pred_count,e_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per Image : 0.125185 sec.\n"
     ]
    }
   ],
   "source": [
    "### Average time per Image\n",
    "print('Average time per Image : {:03f} sec.'.format(time_per_face(img_len,e_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum size of face to be detected in custom datasets: (64,64)\n"
     ]
    }
   ],
   "source": [
    "siz=minFace(cus_test_dires)\n",
    "print('minimum size of face to be detected in custom datasets: ({},{})'.format(siz,siz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum size of face to be detected in custom datasets: (512,512)\n"
     ]
    }
   ],
   "source": [
    "siz=maxFace(cus_test_dires)\n",
    "print('maximum size of face to be detected in custom datasets: ({},{})'.format(siz,siz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the result of all detected and failure images in Result/custom\n",
    "for img_dire in cus_test_dires:\n",
    "    img=cv2.imread(img_dire)\n",
    "    img_name=img_dire.split('/')[-1].split('.')[0]\n",
    "    gray_img=bgr2gray(img)\n",
    "    faces_rect = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=9)\n",
    "    for (x, y, w, h) in faces_rect:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    save_dire=join(paths['res_cus'],'{}.jpg'.format(img_name))\n",
    "    cv2.imwrite(save_dire,img)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_test_dires=glob(paths['public_p_test']+'/*jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_t_p,_,_=test(classifier=pretrained_cascade,dire=pub_test_dires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_count_pub,e_t_pub,img_len_pub=test(classifier=haar_cascade,dire=pub_test_dires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Public dataset: 73.41082455503087%\n"
     ]
    }
   ],
   "source": [
    "## Accuracy of the Public_face detection\n",
    "print('Accuracy on Public dataset: {}%'.format(get_acc(g_t_p,pred_count_pub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per face on Public dataset: 0.002568 sec.\n"
     ]
    }
   ],
   "source": [
    "### Average time per face \n",
    "print('Average time per face on Public dataset: {:03f} sec.'.format(time_per_face(pred_count_pub,e_t_pub)))\n",
    "## As each image is single image time for image per time and face per time is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum face size detected in public(celeba) dataset (64,64).\n"
     ]
    }
   ],
   "source": [
    "### minimum size of detectable face \n",
    "siz=minFace(pub_test_dires)\n",
    "print('minimum face size detected in public(celeba) dataset ({},{}).'.format(siz,siz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum face size detected in public(celeba) dataset (128,128).\n"
     ]
    }
   ],
   "source": [
    "### minimum size of detectable face \n",
    "siz=maxFace(pub_test_dires)\n",
    "print('maximum face size detected in public(celeba) dataset ({},{}).'.format(siz,siz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the result of all detected and failure images in Result/\n",
    "for img_dire in pub_test_dires:\n",
    "    img=cv2.imread(img_dire)\n",
    "    img_name=img_dire.split('/')[-1].split('.')[0]\n",
    "    gray_img=bgr2gray(img)\n",
    "    faces_rect = haar_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=9)\n",
    "    for (x, y, w, h) in faces_rect:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    save_dire=join(paths['res_pub'],'{}.jpg'.format(img_name))\n",
    "    cv2.imwrite(save_dire,img)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c93af7433719cf61beb232a937287b5f6ac44c5a03632b389ba7312dbdbeed85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
